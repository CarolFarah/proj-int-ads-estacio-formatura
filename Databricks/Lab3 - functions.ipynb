{"cells":[{"cell_type":"markdown","source":["###### Função que verifica se há um outro arquivo caracterizado como tabela bronze e, caso haja, mescla o novo dataframe pandas com o antigo retirando as linhas repetidas sobreescrevendo o arquivo anterior."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"167819f4-ecf2-493c-b3f6-2ed6f17b7f9d","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["def spark_df_to_bronze(df, mnt_folder):\n    \n    df = df.select([df[c].cast('string') for c in df.columns])\n    \n    try:\n        bronze_df = spark.read.parquet(mnt_folder)\n        \n    except:\n        print(\"Arquivo não encontrado. Novo arquivo adicionado com sucesso.\")\n        hist_df = df\n    \n    else:\n        print('Histórico encontrado.')\n        bronze_df = spark.read.parquet(mnt_folder)\n        hist_df = df.union(bronze_df).distinct()\n        \n    hist_df.write.mode('overwrite').parquet(mnt_folder)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8c1b0c86-c86a-40de-96ab-bd80a30390ae","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["###### Função que verifica se há um outro arquivo caracterizado como tabela prata e, caso haja, mescla o novo dataframe pandas com o antigo retirando as linhas repetidas sobreescrevendo o arquivo anterior."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"988dd170-5573-4f1d-99a9-5011de4608ac","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["def spark_df_to_silver(df, mnt_folder):\n    \n    try:\n        silver_df =  spark.read.parquet(mnt_folder)\n        \n    except:\n        print(\"Arquivo não encontrado. Novo arquivo adicionado com sucesso.\")\n        hist_df = df\n    \n    else:\n        print('Histórico encontrado.')\n        silver_df =  spark.read.parquet(mnt_folder)\n        hist_df = df.union(silver_df).distinct()\n    \n    hist_df.write.mode('overwrite').parquet(mnt_folder)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"88b1f48e-900b-4c0b-94fe-5d138ac33817","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Função de inserção de dados no banco"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7c4a2081-fbfb-44d4-8fa1-2c964dbfa9f7","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["def insert_a_data_in_db(df, name_table):\n    \n    try:\n        import msal\n    except:\n        print('Biblioteca não encontrada. Iniciando a instalação.')\n        !pip install msal\n        import msal\n    \"\"\"\n    Função que recebe o nome da tabela como parâmetro, retorna a inserção no banco de dados informado\n    insert_table_in_db(name_table_db).\n    retorna a inserção no banco de dados informado\n    Se a tabela não existir no banco de dados ela será criada,\n    caso a tabela já existir ela será substituída e uma nova será criada com os novos dados.\n    \"\"\"\n      \n    #Autoridade:\n    MSAL_authority = 'https://login.windows.net/b4920c82-7581-491a-9dab-cd2ade2f3ebd'\n   \n    #url do recurso database\n    resource_url = 'https://database.windows.net/.default'\n   \n    # Service Principal Client ID - Criado em secrets no Key Vault\n    service_principal_id = dbutils.secrets.get(scope = 'scope-adb-estudos', key = 'app-reg-adb')\n       \n    # Databricks Service - Criado em secrets no Key Vault\n    service_principal_secret = dbutils.secrets.get(scope = 'scope-adb-estudos', key = 'app-user-databricks')\n    \n   # String (url) de conexão ao Azure SQL Server\n    jdbcUrl = f'jdbc:sqlserver://sql-estudo.database.windows.net:1433;database=db-estudos'\n    \n    #Criando a instância que sera usada durante todo o ciclo de vida do aplicativo.\n    instance = msal.ConfidentialClientApplication(service_principal_id, service_principal_secret, MSAL_authority)\n   \n   #Enviando solicitação ao AAD para obter um token.\n    token = instance.acquire_token_for_client(resource_url)\n   \n   #acesando o token\n    access_token = token['access_token']\n   \n    try:\n        table = (df\n                 .write\n                 .format('jdbc')\n                 .mode('overwrite')\n                 .option('url',  jdbcUrl)\n                 .option('dbtable', name_table)\n                 .option('accessToken', access_token)\n                 .save())\n        # df_pocco.write.format(jdbc)(url, name_table_db)\n        print('\\n\\n Tabela inserida no banco de dados com sucesso! \\n\\n')\n    except pyspark.sql.utils.AnalysisException:\n        print(f'Erro! Tabela já existe no banco de dados, renomeie o nome da tabela para proseguir')\n        return pyspark.sql.utils.AnalysisException\n    \n    return table"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"38d531cc-5024-4bf5-acc5-1467cc90acbc","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"funcoes","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":445886021143067}},"nbformat":4,"nbformat_minor":0}
